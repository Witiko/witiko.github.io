---
layout: post
title: 'Static analysis of expl3 programs (2): Requirements'
tags:
  - expl3
  - LaTeX
  - programming
  - devlog
date: 2024-06-27
last_modified_at: 2024-08-09
---

This is my second devlog post for the development of a static analysis tool (so-called *linter*) for the expl3 programming language, which would help developers to discover bugs in their expl3 programs before even running them.

In my [previous post][4], I introduced the idea of linters and why it makes sense to have one for expl3. In this post, I will outline the requirements for the linter. These will form the basis of the design and the implementation.

# Functional requirements

The linter should accept a list of input expl3 files. Then, the linter should process each input file and print out issues it has identified with the file.

Initially, the linter should recognize at least the following types of issues:

- Style:
  - Overly long lines
  - Missing stylistic white-spaces
  - Malformed names of functions, variables, constants, quarks, and scan marks
- Functions:
  - Multiply defined functions and function variants
  - Calling undefined functions and function variants
  - Calling [deprecated and removed][2] functions
  - Unknown argument specifiers
  - Unexpected function call arguments
  - Unused private functions and function variants
- Variables:
  - Multiply declared variables and constants
  - Using undefined variables and constants
  - Using variables of incompatible types
  - Using deprecated and removed variables and constants
  - Setting constants and undeclared variables
  - Unused variables and constants
  - Locally setting global variables and vice versa

# Non-functional requirements

## Issues

The linter should make distinction between two types of issues: warnings and errors. As a rule of thumb, whereas warnings are suggestions about best practices, errors will likely result in runtime errors.

Here are three examples of warnings:

- Missing stylistic white-spaces around curly braces
- Using deprecated functions and variables
- Unused variable or constant

Here are three examples of errors:

- Using an undefined message
- Calling a function with a `V`-type argument with a variable or constant that does not support `V`-type expansion
- Multiply declared variable or constant

The overriding design goal for the initial releases of the linter should be the simplicity of implementation and robustness to unexpected input. For all issues, the linter should prefer [precision over recall][1] and only print them out when it is reasonably certain that it has understood the code, even at the expense of potentially missing some issues.

Each issue should be assigned a unique identifier. Using these identifiers, issues can be disabled globally using a config file, for individual input files from the command-line, and for sections of code or individual lines of code using TeX comments.

## Architecture

To make the linter easy to use in continuous integration pipelines, it should be written in Lua 5.3 using just the standard Lua library. One possible exception is checking whether functions, variables, and other symbols from the input files are expl3 build-ins. This may require using the `texlua` interpreter and a minimal TeX distribution that includes the LaTeX3 kernel, at least initially.

The linter should process input files in a series of discrete steps, which should be represented as Lua modules. Users should be able to import the modules into their Lua code and use them independently on the rest of the linter.

Each step should process the input received from the previous step, identify any issues with the input, and transform the input to an output format appropriate for the next step. The default command-line script for the linter should execute all steps and print out issues from all steps. Users should be able to easily adapt the default script in the following ways:

1. Change how the linter discovers input files.
2. Change or replace processing steps or insert additional steps.
3. Change how the linter reacts to issues with the input files.

**UPDATE (2024-08-01):** As discussed in [the status update from July][5], the linter should integrate easily with text editors. Therefore, the linter should either directly support the [language server protocol (LSP)][6] or be designed in a way that makes it easy to write an LSP wrapper for it.

## Validation

As a part of the test-driven development paradigm, all issues identified by a processing step should have at least one associated test in the code repository of the linter. All tests should be executed periodically during the development of the linter.

As a part of the dogfooding paradigm, the linter should be used in the continuous integration pipeline of [the Markdown Package for TeX][3] since the initial releases of the linter in order to collect early user feedback. Other early adopters are also welcome to try the initial releases of the linter and report issues to its code repository.

At some point, a larger-scale validation should be conducted as an experimental part of a TUGboat article that will introduce the linter to the wider TeX community. In this validation, all expl3 packages from current and historical TeX Live distributions should be processed with the linter. The results should be evaluated both quantitatively and qualitatively. While the quantitative evaluation should focus mainly on trends in how expl3 is used in packages, the qualitative evaluation should explore the shortcomings of the linter and ideas for future improvements.

## License terms (UPDATE: 2024-08-02)
The linter should be [free software][8] and licensed under [the GNU General Public License (GNU GPL) 3.0][9] or [similar][10].

On the first glance, it might seems appropriate to release the linter under a more permissive license such as [the GNU Lesser General Public License (GNU LGPL) 3.0][7]. This way, proprietary software could still use it without modification but any derived works would need to be free. However, as discussed in section *Architecture*, the linter should be modular and allow the insertion of additional processing steps without creating a derived work. Under GNU LGPL, a company might use the linter with extra proprietary steps, which seems undesirable.

# Related work (UPDATE: 2024-08-09)

As discussed in [the status update from July][5], there is plenty related work in the static analysis of TeX programs and documents. This related work should be considered in the design of the linter and reused whenever it is appropriate and enabled by the license.

## Unravel

[The unravel package][11] by Bruno Le Floch analyses of expl3 programs as well as TeX programs and documents in general. The package was suggested as related work by Joseph Wright in personal correspondence.

Unlike a linter, which performs _static_ analysis by leafing through the code and makes suggestions, unravel is a _debugger_ that is used for _dynamic_ analysis and allows the user to step through the execution of code while providing extra information about the state of TeX. Unravel is written in expl3 and emulates TeX primitives using expl3 functions. It has been released under the LaTeX Project Public License (LPPL) 1.3c.

While both linters and debuggers are valuable in producing bug-free software, linters prevent bugs by proactively pointing out potential bugs without any user interaction, whereas debuggers are typically used interactively to determine the cause of a bug after it has already manifested.

## Chktex, chklref, cmdtrack, lacheck, match_parens, nag, and tex2tok

The Comprehensive TeX Archive Network (CTAN) lists related software projects on the topics of [debuging support][12] and [LaTeX quality][13], some of which I list in this section.

[The chktex package][14] by Jens T. Berger Thielemann is a linter for the static analysis of LaTeX documents. It has been written in ANSI C and released under the GNU GPL 2.0 license. The types of issues with the input files and how they are reported to the user can be configured to some extent from the command-line and using configuration files to a larger extent. Chktex is extensible and, in addition to the configuration of existing issues, it allows the definition of new types of issues using regular expressions.

[The lacheck package][17] by Kresten Krab Thorup is a linter for the static analysis of LaTeX documents. Similarly to chktex, lacheck has been written in ANSI C and released under the GNU GPL 1.0 license. Unlike chktex, lacheck cannot be configured either from the command-line or using configuration files.

[The chklref package][15] by Jérôme Lelong is a linter for the static analysis of LaTeX documents. It has been written in Perl and released under the GNU GPL 3.0 license. Unlike chktex, chklref focuses just on the detection of unused labels, which often accumulate over the lifetime of a LaTeX document.

[The match_parens package][18] by Wybo Dekker is a linter for the static analysis of expl3 programs as well as TeX programs and documents in general. It has been written in Ruby and released under the GNU GPL 1.0 license. Unlike chktex, match_parens focuses just on the detection of mismatched paired punctuation, such as parentheses, braces, brackets, and quotation marks. As such, it can also be used for the static analysis of natural text as well as programs and documents in programming and markup languages that use paired punctuation in its syntax.

[The cmdtrack package][16] by Michael John Downes is a debugger for the dynamic analysis of LaTeX documents. It has been written in LaTeX and released under the LPPL 1.0 license. It detects unused user-defined commands, which also often accumulate over the lifetime of a LaTeX document, and mentions them in the `.log` file produced during the compilation of a LaTeX document.

[The nag package][19] by Ulrich Michael Schwarz is a debugger for the dynamic analysis of LaTeX documents. Similarly to cmdtrack, nag has also been written in LaTeX and released under the LPPL 1.0 license. It detects the use of obsolete LaTeX commands, document classes, and packages and mentions them in the `.log` file produced during the compilation of a LaTeX document.

[The tex2tok package][20] by Jonathan Fine is a debugger for the dynamic analysis of expl3 programs as well as TeX programs and documents in general. It has been written in TeX and released under the GNU GPL 2.0 license. It executes a TeX file and produces a new `.tok` file with a list of TeX tokens in the file. Compared to static analysis, the dynamic analysis ensures correct category codes. However, it requires the execution of the TeX file, which may take long or never complete in the presence of bugs in the code.

## Luacheck and flake8

[Luacheck][21] by Peter Melnichenko and [flake8][22] by Tarek Ziade are linters for the static analysis of Lua and Python programs, respectively. They have been written in Lua and Python, respectively, and released under the MIT license. Both tools are widely used and should inform the design of my tool in terms of architecture, configuration, and extensibility.

Similar to chktex, the types of issues with the input files and how they are reported to the user can be configured from the command-line and using configuration files. Additionally, the reporting can also be enabled or disabled in the code of the analyzed program using inline comments.

Unlike luacheck, which is not extensible at the time of writing and only allows the configuration of existing issues, flake8 supports Python extensions that can add support for new types of issues.

## TeXLab and digestif

[TeXLab][23] by Eric and Patrick Förscher and [digestif][24] by Augusto Stoffel are [language servers][6] for the static analysis of TeX programs and documents. They have been written in Rust and Lua, respectively, and released under the GNU GPL 3.0 license. Whereas TeXLab focuses on LaTeX documents, digestif also supports other formats such as ConTeXt and GNU Texinfo. Neither TeXLab nor digestif support expl3 code at the time of writing.

In terms of the programming language, license, and scope, digestif seems like the most related work to my tool and should provide many opportunities for inspiration and code reuse.

# Conclusion

In this post, I outlined the requirements for the linter and related work in the analysis of TeX programs. In the next post, I will analyze the requirements, discuss the design of the linter, and create a code repository for the linter. Then, I will continue by implementing the first processing step for the linter.

 [1]: https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall
 [2]: https://github.com/latex3/latex3/blob/main/l3kernel/doc/l3obsolete.txt
 [3]: https://github.com/witiko/markdown
 [4]: /Expl3-Linter-1
 [5]: /Expl3-Linter-2.5
 [6]: https://microsoft.github.io/language-server-protocol/
 [7]: https://www.gnu.org/licenses/lgpl-3.0.en.html
 [8]: https://www.gnu.org/philosophy/free-sw.html
 [9]: https://www.gnu.org/licenses/gpl-3.0.html
 [10]: https://www.gnu.org/licenses/license-list.html#GPLCompatibleLicenses
 [11]: https://ctan.org/pkg/unravel
 [12]: https://ctan.org/topic/debug-supp
 [13]: https://ctan.org/topic/latex-qual
 [14]: https://ctan.org/pkg/chktex
 [15]: https://ctan.org/pkg/chklref
 [16]: https://ctan.org/pkg/cmdtrack
 [17]: https://ctan.org/pkg/lacheck
 [18]: https://ctan.org/pkg/match_parens
 [19]: https://ctan.org/pkg/nag
 [20]: https://ctan.org/pkg/tex2tok
 [21]: https://github.com/mpeterv/luacheck
 [22]: https://github.com/pycqa/flake8
 [23]: https://ctan.org/pkg/texlab
 [24]: https://ctan.org/pkg/digestif
